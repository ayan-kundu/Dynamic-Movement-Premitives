# Dynamic-Movement-Premitives:DMP
This repo is base on Imitation Learning using Learning from Demonstration(LfD)

mitation learning:

Learning from Demonstration(LfD):-

Application1:-Pick and place
The graphs I attached is made using pic and place operation. These graphs shows a good amount of imitation learning, the robot is capable of.
Attach pic
In Pick and place I got an idea of Food unloading to dish from microwave where pick pose would be the food inside the microwave and the place pose would be the plate position.
Attach pic


Application2:Wave gesture
It is able to imitate hand wave trajectory. So if I put a palm structure on it gripper it can wave from any position and it will carry on waving for a certain time irrespective if its initial body pose. 
Attach pic


Dmp visualisation:
Show outputs
Show plots
Attach pic


Issue I am facing currently:
Gripper not working: 
>>>is_gripper_moving
0
---Burn ATOM to its latest version 4.2

I was just wondering if we could do something with this in Freshersâ€™ stall to demonstrate and introduce students with mycobot as not every students are familiar with this to be fair. The dmp graphs are good so that we can put it under display if you want or think about it.

Future aspect: putting vision 
After I sort this gripper issue, it would be ready but I was thinking to put computer vision so that it can automatically pick (no need to give pick position anymore) and place to the given place position. 
